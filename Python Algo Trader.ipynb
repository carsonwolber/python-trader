{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4308b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  503 of 503 completed\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.regression.rolling import RollingOLS\n",
    "import eikon as ek\n",
    "ek.set_app_key('85053106977c410aae4a51a1299cebee57f2d209')\n",
    "import pandas_datareader.data as web\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import yfinance as yf\n",
    "import pandas_ta as ta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\"\"\"\n",
    "find_atr takes input [stock_data] and returns the normalized atr or average \n",
    "true range; atr decomposes range during our period to access volatility\n",
    "\"\"\"\n",
    "def find_atr(stock_data):\n",
    "  atr = ta.atr(high=stock_data['high'], \n",
    "              low=stock_data['low'],\n",
    "              close=stock_data['close'])\n",
    "  return atr.sub(atr.mean()).div(atr.std())\n",
    "\n",
    "\"\"\"\n",
    "find_macd returns moving average convergence/divergence\n",
    "\"\"\"\n",
    "def find_macd(close):\n",
    "  macd = ta.macd(close=close, length=20).iloc[:,0]\n",
    "  return macd.sub(macd.mean()).div(macd.std())\n",
    "\n",
    "\n",
    "\"find_sma returns simple moving average\"\n",
    "def find_sma(close):\n",
    "  sma = ta.sma(close=close, length=20)\n",
    "  return sma.sub(sma.mean()).div(sma.std())\n",
    "\n",
    "\n",
    "'''\n",
    "Part 1: Data Cleaning\n",
    "1. using eikon api, get s&p500 company names\n",
    "2. set an 8 year window of data to examine\n",
    "3. filter any dots out with dashs to avoid errors\n",
    "4. create a list of all s&p 500 tickers\n",
    "5. use yfinance to generate constituent data\n",
    "6. clean constituent data\n",
    "'''\n",
    "sp500 = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')[0]\n",
    "start = '2016-02-24'\n",
    "end = '2024-02-24'\n",
    "sp500['Symbol'] = sp500['Symbol'].str.replace('.', '-')\n",
    "sp500_tickers = sp500['Symbol'].unique().tolist()\n",
    "data = yf.download(tickers= sp500_tickers, start=start, end=end).stack()\n",
    "data.index.names = ['date', 'ticker']\n",
    "data.columns = data.columns.str.lower()\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Part 2: Indicators\n",
    "1. Garman-Klass Volatility\n",
    "2. RSI\n",
    "3. Bollinger Bands\n",
    "4. ATR\n",
    "5. MACD\n",
    "6. Dollar Volume\n",
    "7. SMA\n",
    "\"\"\"\n",
    "# GKV = (log(high)- log(low)^2)/2 - (2log(2) -1)(log(adj close) - log(open))^2\n",
    "data['gkv'] = ((np.log(data['high']) - np.log(data['low']))**2)/2\n",
    "- (2*np.log(2)-1) * ((np.log(data['adj close']) - np.log(data['open'])**2 ))\n",
    "data['rsi'] = data.groupby(level=1)['adj close'].transform(lambda x: ta.rsi(close=x, length=20))\n",
    "data['bb_low'] = data.groupby(level=1)['adj close'].transform(lambda x: ta.bbands(close=np.log1p(x),length=20).iloc[:,0])\n",
    "data['bb_mid'] = data.groupby(level=1)['adj close'].transform(lambda x: ta.bbands(close=np.log1p(x),\n",
    "length=20).iloc[:,1])\n",
    "data['bb_high'] = data.groupby(level=1)['adj close'].transform(lambda x: ta.bbands(close=np.log1p(x),\n",
    "length=20).iloc[:,2])\n",
    "data['atr'] = data.groupby(level=1, group_keys=False).apply(find_atr)\n",
    "data['macd'] = data.groupby(level=1, group_keys=False)['adj close'].apply(find_macd)\n",
    "data['dv'] = (data['adj close']*data['volume'])/1e6\n",
    "data['sma'] = data.groupby(level=1, group_keys=False)['adj close'].apply(find_sma)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Part 3: Aggregate monthly level and filter for top 100 most liquid stocks for\n",
    "each month\n",
    "\"\"\"\n",
    "last_cols = [c for c in data.columns.unique(0) if c not in ['dv', 'volume', \n",
    "                                                            'open','high',\n",
    "                                                            'low', 'close']]\n",
    "aggregate = pd.concat([data.unstack('ticker')['dv'].resample('M').mean().stack('ticker').to_frame('dv'),\n",
    "data.unstack()[last_cols].resample('M').last().stack('ticker')],axis=1).dropna()\n",
    "\n",
    "\n",
    "#find 5-year rolling average of dv to filter\n",
    "aggregate['dv'] = (aggregate['dv'].unstack('ticker').rolling(5*12).mean().stack())\n",
    "aggregate['dv_rank'] = (aggregate.groupby('date')['dv'].rank(ascending=False))\n",
    "\n",
    "#isolate top 100\n",
    "aggregate[aggregate['dv_rank']<100].drop(['dv', 'dv_rank'], axis=1)\n",
    "\n",
    "\"\"\"\n",
    "Part 4: Find monthly returns for different time horizons as features\n",
    "\"\"\"\n",
    "\n",
    "\"returns 3 month returns for each ticker while clipping outliers at 5% threshold\"\n",
    "def get_returns(data):\n",
    "  outlier = 0.05\n",
    "  lags = [1,3,6,9,12]\n",
    "  for lag in lags:\n",
    "    data[f'return_{lag}m'] = (data['adj close']\n",
    "                           .pct_change(lag)\n",
    "                           .pipe(lambda x: x.clip(lower=x.quantile(outlier),\n",
    "                                                  upper= x.quantile(1-outlier)))\n",
    "                           .add(1)\n",
    "                           .pow(1/lag)\n",
    "                           .sub(1)\n",
    "                           )\n",
    "    return data\n",
    "  \n",
    "  aggregate = aggregate.groupby(level=1, group_keys=False).apply(get_returns).dropna()\n",
    "\n",
    "\n",
    "  \"\"\"\n",
    "  Part 5:\n",
    "  Download Fama-French Factors and Calculate Rolling Factor Betas\n",
    "  \"\"\"\n",
    "  ff_data = web.DataReader('F-F_Research_Data_5_Factors_2x3',\n",
    "                 'famafrench',\n",
    "                 start = '2010')[0]\n",
    "\n",
    "  ff_data.index = ff_data.index.to_timestamp()\n",
    "\n",
    "  print(ff_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d3dd49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c26115",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
